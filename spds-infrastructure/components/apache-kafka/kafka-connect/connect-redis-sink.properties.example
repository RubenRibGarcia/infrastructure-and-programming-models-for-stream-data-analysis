name=
connector.class=RedisSinkConnector
tasks.max=1

# the file from where the connector should read lines and publish to kafka, this is inside the docker container so we have this
# mount in the compose file mapping this to an external file where we have rights to read and write and use that as input.
redis.host = "redis"
redis.port = "6379"
redis.database = "database"
redis.password = "password"
redis.connection_timeout_ms = 5000
redis.max_idle = 5
redis.max_total = 5
redis.min_idle = 0
redis.command = RPUSH
redis.key = processed_data_output

kafka.topic=kafka_output

# We override the defaults for this connector example as we want to quickly just validate it for now.
key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.storage.StringConverter

# We don't need converters for the simple example
key.converter.schemas.enable=false
value.converter.schemas.enable=false
